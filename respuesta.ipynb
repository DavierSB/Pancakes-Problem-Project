{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica 1: Búsqueda\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem and Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import heapq\n",
    "import math\n",
    "import sys\n",
    "import copy\n",
    "from collections import defaultdict, deque, Counter\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class Problem(object):\n",
    "    \"\"\"The abstract class for a formal problem. A new domain subclasses this,\n",
    "    overriding `actions` and `results`, and perhaps other methods.\n",
    "    The default heuristic is 0 and the default action cost is 1 for all states.\n",
    "    When you create an instance of a subclass, specify `initial`, and `goal` states \n",
    "    (or give an `is_goal` method) and perhaps other keyword args for the subclass.\"\"\"\n",
    "\n",
    "    def __init__(self, initial=None, goal=None, **kwds): \n",
    "        self.__dict__.update(initial=initial, goal=goal, **kwds) \n",
    "        \n",
    "    def actions(self, state):        raise NotImplementedError\n",
    "    def result(self, state, action): raise NotImplementedError\n",
    "    def is_goal(self, state):        return state == self.goal\n",
    "    def action_cost(self, s, a, s1): return 1\n",
    "    def h(self, node):               return 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({!r}, {!r})'.format(\n",
    "            type(self).__name__, self.initial, self.goal)\n",
    "    \n",
    "\n",
    "class Node:\n",
    "    \"A Node in a search tree.\"\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.__dict__.update(state=state, parent=parent, action=action, path_cost=path_cost)\n",
    "\n",
    "    def __repr__(self): return '<{}>'.format(self.state)\n",
    "    def __len__(self): return 0 if self.parent is None else (1 + len(self.parent))\n",
    "    def __lt__(self, other): return self.path_cost < other.path_cost\n",
    "    \n",
    "    \n",
    "failure = Node('failure', path_cost=math.inf) # Indicates an algorithm couldn't find a solution.\n",
    "cutoff  = Node('cutoff',  path_cost=math.inf) # Indicates iterative deepening search was cut off.\n",
    "    \n",
    "    \n",
    "def expand(problem, node):\n",
    "    \"Expand a node, generating the children nodes.\"\n",
    "    s = node.state\n",
    "    for action in problem.actions(s):\n",
    "        s1 = problem.result(s, action)\n",
    "        cost = node.path_cost + problem.action_cost(s, action, s1)\n",
    "        yield Node(s1, node, action, cost)\n",
    "        \n",
    "\n",
    "def path_actions(node):\n",
    "    \"The sequence of actions to get to this node.\"\n",
    "    if node.parent is None:\n",
    "        return []  \n",
    "    return path_actions(node.parent) + [node.action]\n",
    "\n",
    "\n",
    "def path_states(node):\n",
    "    \"The sequence of states to get to this node.\"\n",
    "    if node in (cutoff, failure, None): \n",
    "        return []\n",
    "    return path_states(node.parent) + [node.state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIFOQueue = deque\n",
    "\n",
    "LIFOQueue = list\n",
    "\n",
    "class PriorityQueue:\n",
    "    \"\"\"A queue in which the item with minimum f(item) is always popped first.\"\"\"\n",
    "\n",
    "    def __init__(self, items=(), key=lambda x: x): \n",
    "        self.key = key\n",
    "        self.items = [] # a heap of (score, item) pairs\n",
    "        for item in items:\n",
    "            self.add(item)\n",
    "         \n",
    "    def add(self, item):\n",
    "        \"\"\"Add item to the queuez.\"\"\"\n",
    "        pair = (self.key(item), item)\n",
    "        heapq.heappush(self.items, pair)\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"Pop and return the item with min f(item) value.\"\"\"\n",
    "        return heapq.heappop(self.items)[1]\n",
    "    \n",
    "    def top(self): return self.items[0][1]\n",
    "\n",
    "    def __len__(self): return len(self.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Algorithms\n",
    "\n",
    "Con best-first search al variar la función *f(n)* se tienen diferentes algoritmos de búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def best_first_search(problem, f):\n",
    "    \"Search nodes with minimum f(node) value first.\"\n",
    "    node = Node(problem.initial)\n",
    "    frontier = PriorityQueue([node], key=f)\n",
    "    reached = {problem.initial: node}\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        if problem.is_goal(node.state):\n",
    "            return node\n",
    "        for child in expand(problem, node):\n",
    "            s = child.state\n",
    "            if s not in reached or child.path_cost < reached[s].path_cost:\n",
    "                reached[s] = child\n",
    "                frontier.add(child)\n",
    "    return failure\n",
    "\n",
    "\n",
    "def best_first_tree_search(problem, f):\n",
    "    \"A version of best_first_search without the `reached` table.\"\n",
    "    frontier = PriorityQueue([Node(problem.initial)], key=f)\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        if problem.is_goal(node.state):\n",
    "            return node\n",
    "        for child in expand(problem, node):\n",
    "            if not is_cycle(child):\n",
    "                frontier.add(child)\n",
    "    return failure\n",
    "\n",
    "\n",
    "def g(n): return n.path_cost\n",
    "\n",
    "\n",
    "def astar_search(problem, h=None):\n",
    "    \"\"\"Search nodes with minimum f(n) = g(n) + h(n).\"\"\"\n",
    "    h = h or problem.h\n",
    "    return best_first_search(problem, f=lambda n: g(n) + h(n))\n",
    "\n",
    "\n",
    "def astar_tree_search(problem, h=None):\n",
    "    \"\"\"Search nodes with minimum f(n) = g(n) + h(n), with no `reached` table.\"\"\"\n",
    "    h = h or problem.h\n",
    "    return best_first_tree_search(problem, f=lambda n: g(n) + h(n))\n",
    "\n",
    "\n",
    "def weighted_astar_search(problem, h=None, weight=1.4):\n",
    "    \"\"\"Search nodes with minimum f(n) = g(n) + weight * h(n).\"\"\"\n",
    "    h = h or problem.h\n",
    "    return best_first_search(problem, f=lambda n: g(n) + weight * h(n))\n",
    "\n",
    "        \n",
    "def greedy_bfs(problem, h=None):\n",
    "    \"\"\"Search nodes with minimum h(n).\"\"\"\n",
    "    h = h or problem.h\n",
    "    return best_first_search(problem, f=h)\n",
    "\n",
    "\n",
    "def uniform_cost_search(problem):\n",
    "    \"Search nodes with minimum path cost first.\"\n",
    "    return best_first_search(problem, f=g)\n",
    "\n",
    "\n",
    "def breadth_first_bfs(problem):\n",
    "    \"Search shallowest nodes in the search tree first; using best-first.\"\n",
    "    return best_first_search(problem, f=len)\n",
    "\n",
    "\n",
    "def depth_first_bfs(problem):\n",
    "    \"Search deepest nodes in the search tree first; using best-first.\"\n",
    "    return best_first_search(problem, f=lambda n: -len(n))\n",
    "\n",
    "\n",
    "def is_cycle(node, k=30):\n",
    "    \"Does this node form a cycle of length k or less?\"\n",
    "    def find_cycle(ancestor, k):\n",
    "        return (ancestor is not None and k > 0 and\n",
    "                (ancestor.state == node.state or find_cycle(ancestor.parent, k - 1)))\n",
    "    return find_cycle(node.parent, k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first_search(problem):\n",
    "    \"Search shallowest nodes in the search tree first.\"\n",
    "    node = Node(problem.initial)\n",
    "    if problem.is_goal(problem.initial):\n",
    "        return node\n",
    "    frontier = FIFOQueue([node])\n",
    "    reached = {problem.initial}\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        for child in expand(problem, node):\n",
    "            s = child.state\n",
    "            if problem.is_goal(s):\n",
    "                return child\n",
    "            if s not in reached:\n",
    "                reached.add(s)\n",
    "                frontier.appendleft(child)\n",
    "    return failure\n",
    "\n",
    "\n",
    "def iterative_deepening_search(problem):\n",
    "    \"Do depth-limited search with increasing depth limits.\"\n",
    "    for limit in range(1, sys.maxsize):\n",
    "        result = depth_limited_search(problem, limit)\n",
    "        if result != cutoff:\n",
    "            return result\n",
    "        \n",
    "        \n",
    "def depth_limited_search(problem, limit=10):\n",
    "    \"Search deepest nodes in the search tree first.\"\n",
    "    frontier = LIFOQueue([Node(problem.initial)])\n",
    "    result = failure\n",
    "    while frontier:\n",
    "        node = frontier.pop()\n",
    "        if problem.is_goal(node.state):\n",
    "            return node\n",
    "        elif len(node) >= limit:\n",
    "            result = cutoff\n",
    "        elif not is_cycle(node):\n",
    "            for child in expand(problem, node):\n",
    "                frontier.append(child)\n",
    "    return result\n",
    "\n",
    "\n",
    "def depth_first_recursive_search(problem, node=None):\n",
    "    if node is None: \n",
    "        node = Node(problem.initial)\n",
    "    if problem.is_goal(node.state):\n",
    "        return node\n",
    "    elif is_cycle(node):\n",
    "        return failure\n",
    "    else:\n",
    "        for child in expand(problem, node):\n",
    "            result = depth_first_recursive_search(problem, child)\n",
    "            if result:\n",
    "                return result\n",
    "        return failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional Best-First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_best_first_search(problem_f, f_f, problem_b, f_b, terminated):\n",
    "    node_f = Node(problem_f.initial)\n",
    "    node_b = Node(problem_f.goal)\n",
    "    frontier_f, reached_f = PriorityQueue([node_f], key=f_f), {node_f.state: node_f}\n",
    "    frontier_b, reached_b = PriorityQueue([node_b], key=f_b), {node_b.state: node_b}\n",
    "    solution = failure\n",
    "    while frontier_f and frontier_b and not terminated(solution, frontier_f, frontier_b):\n",
    "        def S1(node, f):\n",
    "            return str(int(f(node))) + ' ' + str(path_states(node))\n",
    "        if f_f(frontier_f.top()) < f_b(frontier_b.top()):\n",
    "            solution = proceed('f', problem_f, frontier_f, reached_f, reached_b, solution)\n",
    "        else:\n",
    "            solution = proceed('b', problem_b, frontier_b, reached_b, reached_f, solution)\n",
    "    return solution\n",
    "\n",
    "def inverse_problem(problem):\n",
    "    if isinstance(problem, CountCalls):\n",
    "        return CountCalls(inverse_problem(problem._object))\n",
    "    else:\n",
    "        inv = copy.copy(problem)\n",
    "        inv.initial = inv.goal\n",
    "        inv.goal = inv.initial\n",
    "        inv.h = inv.reverse_h\n",
    "        return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_uniform_cost_search(problem_f):\n",
    "    def terminated(solution, frontier_f, frontier_b):\n",
    "        n_f, n_b = frontier_f.top(), frontier_b.top()\n",
    "        return g(n_f) + g(n_b) > g(solution)\n",
    "    return bidirectional_best_first_search(problem_f, g, inverse_problem(problem_f), g, terminated)\n",
    "\n",
    "def bidirectional_astar_search(problem_f):\n",
    "    def terminated(solution, frontier_f, frontier_b):\n",
    "        nf, nb = frontier_f.top(), frontier_b.top()\n",
    "        return g(nf) + g(nb) > g(solution)\n",
    "    problem_b = inverse_problem(problem_f)\n",
    "    return bidirectional_best_first_search(problem_f, lambda n: g(n) + problem_f.h(n),\n",
    "                                           problem_b, lambda n: g(n) + problem_b.h(n), \n",
    "                                           terminated)\n",
    "   \n",
    "\n",
    "def proceed(direction, problem, frontier, reached, reached2, solution):\n",
    "    node = frontier.pop()\n",
    "    for child in expand(problem, node):\n",
    "        s = child.state\n",
    "        if s not in reached or child.path_cost < reached[s].path_cost:\n",
    "            frontier.add(child)\n",
    "            reached[s] = child\n",
    "            if s in reached2: # Frontiers collide; solution found\n",
    "                solution2 = (join_nodes(child, reached2[s]) if direction == 'f' else\n",
    "                             join_nodes(reached2[s], child))\n",
    "                #print('solution', path_states(solution2), solution2.path_cost, \n",
    "                # path_states(child), path_states(reached2[s]))\n",
    "                if solution2.path_cost < solution.path_cost:\n",
    "                    solution = solution2\n",
    "    return solution\n",
    "\n",
    "S = path_states\n",
    "\n",
    "#A-S-R + B-P-R => A-S-R-P + B-P\n",
    "def join_nodes(nf, nb):\n",
    "    \"\"\"Join the reverse of the backward node nb to the forward node nf.\"\"\"\n",
    "    #print('join', S(nf), S(nb))\n",
    "    join = nf\n",
    "    while nb.parent is not None:\n",
    "        cost = join.path_cost + nb.path_cost - nb.parent.path_cost\n",
    "        join = Node(nb.parent.state, join, nb.action, cost)\n",
    "        nb = nb.parent\n",
    "        #print('  now join', S(join), 'with nb', S(nb), 'parent', S(nb.parent))\n",
    "    return join\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(L, i, j):\n",
    "    temp = L[i]\n",
    "    L[i] = L[j]\n",
    "    L[j] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pancake Sorting Problems\n",
    "\n",
    "Dada una pila de pancakes de varios tamaños, ¿puedes ordenarlos en una pila de tamaños decrecientes, del más grande en la parte inferior al más pequeño en la parte superior? Tienes una espátula con la que puedes voltear los `i` pancakes de arriba. Esto se muestra a continuación para `i = 3`; en la parte superior, la espátula agarra los primeros tres pancakes; en la parte inferior los vemos volteados:\n",
    "\n",
    "![](images/Pancake_sort_operation.png)\n",
    "\n",
    "¿Cuántas vueltas se necesitarán para ordenar toda la pila? Este es un problema interesante sobre el que Bill Gates ha [escrito](https://people.eecs.berkeley.edu/~christos/papers/Bounds%20For%20Sorting%20By%20Prefix%20Reversal.pdf). Una heurística razonable para este problema es la *gap heuristic*: si observamos panqueques vecinos, por ejemplo, el segundo más pequeño está al lado del tercero más pequeño, está bien; deben permanecer uno al lado del otro. Pero si el 2º más pequeño está al lado del 4º más pequeño, eso es malo: necesitaremos al menos un movimiento para separarlos e insertar el 3º más pequeño entre ellos. La heurística cuenta el número de vecinos que tienen una brecha como esta. En nuestra especificación del problema, los panqueques se clasifican por tamaño: el más pequeño es \"1\", el segundo más pequeño es \"2\", y así sucesivamente, y la representación de un estado es una tupla de estas clasificaciones, de arriba hacia abajo. Por lo tanto, el estado objetivo siempre es `(1, 2, ..., `*n*`)` y el estado inicial (superior) en el diagrama anterior es `(2, 1, 4, 6, 3, 5)` .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1973707439.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[101], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    if abs(self.pos_in_initial[node.state[i]] - self.pos_in_initial[node.state[i + 1]] > 1:\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class PancakeProblem(Problem):\n",
    "    \"\"\"A PancakeProblem the goal is always `tuple(range(1, n+1))`, where the\n",
    "    initial state is a permutation of `range(1, n+1)`. An act is the index `i` \n",
    "    of the top `i` pancakes that will be flipped.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial): \n",
    "        self.initial, self.goal = tuple(initial), tuple(sorted(initial))\n",
    "        self.pos_in_initial = {}\n",
    "        for i in range(0, len(initial)):\n",
    "            self.pos_in_initial[self.initial[i]] = i\n",
    "    \n",
    "    def actions(self, state):\n",
    "        return list(range(len(state)))\n",
    "\n",
    "    def result(self, state, flip_index):\n",
    "        answer = list(state)\n",
    "        for i in range(0, (flip_index>>1) + 1):\n",
    "            swap(answer, flip_index - i, i)\n",
    "        return tuple(answer)\n",
    "    \n",
    "    def h(self, node):\n",
    "        gaps = 0\n",
    "        for i in range(0, len(node.state) - 1):\n",
    "            if abs(node.state[i] - node.state[i + 1]) > 1:\n",
    "                gaps = gaps + 1 \n",
    "        return gaps\n",
    "    \n",
    "    def reverse_h(self, node):\n",
    "        gaps = 0\n",
    "        for i in range(0, len(node.state) - 1):\n",
    "            if abs(self.pos_in_initial[node.state[i]] - self.pos_in_initial[node.state[i + 1]]) > 1:\n",
    "                gaps = gaps + 1 \n",
    "        return gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = PancakeProblem((2, 1, 4, 6, 3, 5))\n",
    "c1 = PancakeProblem((4, 6, 2, 5, 1, 3))\n",
    "c2 = PancakeProblem((1, 3, 7, 5, 2, 6, 4))\n",
    "c3 = PancakeProblem((1, 7, 2, 6, 3, 5, 4))\n",
    "c4 = PancakeProblem((1, 3, 5, 7, 9, 2, 4, 6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Solve a pancake problem\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sln \u001b[38;5;241m=\u001b[39m \u001b[43mbidirectional_astar_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m path_actions(sln), path_states(bidirectional_astar_search(c4))\n",
      "Cell \u001b[0;32mIn[91], line 12\u001b[0m, in \u001b[0;36mbidirectional_astar_search\u001b[0;34m(problem_f)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g(nf) \u001b[38;5;241m+\u001b[39m g(nb) \u001b[38;5;241m>\u001b[39m g(solution)\n\u001b[1;32m     11\u001b[0m problem_b \u001b[38;5;241m=\u001b[39m inverse_problem(problem_f)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbidirectional_best_first_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproblem_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mproblem_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproblem_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mterminated\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[90], line 5\u001b[0m, in \u001b[0;36mbidirectional_best_first_search\u001b[0;34m(problem_f, f_f, problem_b, f_b, terminated)\u001b[0m\n\u001b[1;32m      3\u001b[0m node_b \u001b[38;5;241m=\u001b[39m Node(problem_f\u001b[38;5;241m.\u001b[39mgoal)\n\u001b[1;32m      4\u001b[0m frontier_f, reached_f \u001b[38;5;241m=\u001b[39m PriorityQueue([node_f], key\u001b[38;5;241m=\u001b[39mf_f), {node_f\u001b[38;5;241m.\u001b[39mstate: node_f}\n\u001b[0;32m----> 5\u001b[0m frontier_b, reached_b \u001b[38;5;241m=\u001b[39m \u001b[43mPriorityQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_b\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_b\u001b[49m\u001b[43m)\u001b[49m, {node_b\u001b[38;5;241m.\u001b[39mstate: node_b}\n\u001b[1;32m      6\u001b[0m solution \u001b[38;5;241m=\u001b[39m failure\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frontier_f \u001b[38;5;129;01mand\u001b[39;00m frontier_b \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminated(solution, frontier_f, frontier_b):\n",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m, in \u001b[0;36mPriorityQueue.__init__\u001b[0;34m(self, items, key)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# a heap of (score, item) pairs\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 16\u001b[0m, in \u001b[0;36mPriorityQueue.add\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add item to the queuez.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     pair \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m, item)\n\u001b[1;32m     17\u001b[0m     heapq\u001b[38;5;241m.\u001b[39mheappush(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems, pair)\n",
      "Cell \u001b[0;32mIn[91], line 13\u001b[0m, in \u001b[0;36mbidirectional_astar_search.<locals>.<lambda>\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g(nf) \u001b[38;5;241m+\u001b[39m g(nb) \u001b[38;5;241m>\u001b[39m g(solution)\n\u001b[1;32m     11\u001b[0m problem_b \u001b[38;5;241m=\u001b[39m inverse_problem(problem_f)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bidirectional_best_first_search(problem_f, \u001b[38;5;28;01mlambda\u001b[39;00m n: g(n) \u001b[38;5;241m+\u001b[39m problem_f\u001b[38;5;241m.\u001b[39mh(n),\n\u001b[0;32m---> 13\u001b[0m                                        problem_b, \u001b[38;5;28;01mlambda\u001b[39;00m n: g(n) \u001b[38;5;241m+\u001b[39m \u001b[43mproblem_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m     14\u001b[0m                                        terminated)\n",
      "Cell \u001b[0;32mIn[98], line 31\u001b[0m, in \u001b[0;36mPancakeProblem.reverse_h\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     29\u001b[0m gaps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mstate) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_in_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_in_initial(node\u001b[38;5;241m.\u001b[39mstate[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     32\u001b[0m         gaps \u001b[38;5;241m=\u001b[39m gaps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gaps\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "# Solve a pancake problem\n",
    "sln = bidirectional_astar_search(c4)\n",
    "path_actions(sln), path_states(bidirectional_astar_search(c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 8, 7, 6, 5, 4, 3, 2, 1],\n",
       " [(1, 3, 5, 7, 9, 2, 4, 6, 8),\n",
       "  (9, 7, 5, 3, 1, 2, 4, 6, 8),\n",
       "  (8, 6, 4, 2, 1, 3, 5, 7, 9),\n",
       "  (7, 5, 3, 1, 2, 4, 6, 8, 9),\n",
       "  (6, 4, 2, 1, 3, 5, 7, 8, 9),\n",
       "  (5, 3, 1, 2, 4, 6, 7, 8, 9),\n",
       "  (4, 2, 1, 3, 5, 6, 7, 8, 9),\n",
       "  (3, 1, 2, 4, 5, 6, 7, 8, 9),\n",
       "  (2, 1, 3, 4, 5, 6, 7, 8, 9),\n",
       "  (1, 2, 3, 4, 5, 6, 7, 8, 9)])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sln = astar_search(c4)\n",
    "path_actions(sln), path_states(astar_search(c4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Algoritmos de Búsqueda\n",
    "\n",
    "Usaremos `CountCalls` para envolver el objeto `Problem` de tal manera que las llamadas a sus métodos se deleguen al problema original, pero cada llamada incrementa un contador. Una vez que hemos resuelto el problema, imprimimos un resumen estadísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountCalls:\n",
    "    \"\"\"Delegate all attribute gets to the object, and count them in ._counts\"\"\"\n",
    "    def __init__(self, obj):\n",
    "        self._object = obj\n",
    "        self._counts = Counter()\n",
    "        \n",
    "    def __getattr__(self, attr):\n",
    "        \"Delegate to the original object, after incrementing a counter.\"\n",
    "        self._counts[attr] += 1\n",
    "        return getattr(self._object, attr)\n",
    "\n",
    "        \n",
    "def report(searchers, problems, verbose=True):\n",
    "    \"\"\"Show summary statistics for each searcher (and on each problem unless verbose is false).\"\"\"\n",
    "    for searcher in searchers:\n",
    "        print(searcher.__name__ + ':')\n",
    "        total_counts = Counter()\n",
    "        for p in problems:\n",
    "            prob   = CountCalls(p)\n",
    "            soln   = searcher(prob)\n",
    "            counts = prob._counts; \n",
    "            counts.update(actions=len(soln), cost=soln.path_cost)\n",
    "            total_counts += counts\n",
    "            if verbose: report_counts(counts, str(p)[:40])\n",
    "        report_counts(total_counts, 'TOTAL\\n')\n",
    "        \n",
    "def report_counts(counts, name):\n",
    "    \"\"\"Print one line of the counts report.\"\"\"\n",
    "    print('{:9,d} nodes |{:9,d} goal |{:5.0f} cost |{:8,d} actions | {}'.format(\n",
    "          counts['result'], counts['is_goal'], counts['cost'], counts['actions'], name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astar_search:\n",
      "    1,542 nodes |      258 goal |    7 cost |     264 actions | PancakeProblem((4, 6, 2, 5, 1, 3), (1, 2\n",
      "    4,438 nodes |      635 goal |    8 cost |     642 actions | PancakeProblem((1, 3, 7, 5, 2, 6, 4), (1\n",
      "      343 nodes |       50 goal |    6 cost |      55 actions | PancakeProblem((1, 7, 2, 6, 3, 5, 4), (1\n",
      "    2,538 nodes |      283 goal |    9 cost |     291 actions | PancakeProblem((1, 3, 5, 7, 9, 2, 4, 6, \n",
      "    8,861 nodes |    1,226 goal |   30 cost |   1,252 actions | TOTAL\n",
      "\n",
      "bidirectional_astar_search:\n",
      "      378 nodes |        0 goal |    7 cost |      70 actions | PancakeProblem((4, 6, 2, 5, 1, 3), (1, 2\n",
      "      749 nodes |        0 goal |    8 cost |     115 actions | PancakeProblem((1, 3, 7, 5, 2, 6, 4), (1\n",
      "       35 nodes |        0 goal |    6 cost |      11 actions | PancakeProblem((1, 7, 2, 6, 3, 5, 4), (1\n",
      "      126 nodes |        0 goal |    9 cost |      23 actions | PancakeProblem((1, 3, 5, 7, 9, 2, 4, 6, \n",
      "    1,288 nodes |        0 goal |   30 cost |     219 actions | TOTAL\n",
      "\n",
      "uniform_cost_search:\n",
      "    4,308 nodes |      719 goal |    7 cost |     725 actions | PancakeProblem((4, 6, 2, 5, 1, 3), (1, 2\n",
      "   35,238 nodes |    5,035 goal |    8 cost |   5,042 actions | PancakeProblem((1, 3, 7, 5, 2, 6, 4), (1\n",
      "   25,746 nodes |    3,679 goal |    6 cost |   3,684 actions | PancakeProblem((1, 7, 2, 6, 3, 5, 4), (1\n",
      "2,555,766 nodes |  283,975 goal |    9 cost | 283,983 actions | PancakeProblem((1, 3, 5, 7, 9, 2, 4, 6, \n",
      "2,621,058 nodes |  293,408 goal |   30 cost | 293,434 actions | TOTAL\n",
      "\n",
      "bidirectional_uniform_cost_search:\n",
      "      630 nodes |        0 goal |    7 cost |     112 actions | PancakeProblem((4, 6, 2, 5, 1, 3), (1, 2\n",
      "    1,302 nodes |        0 goal |    8 cost |     194 actions | PancakeProblem((1, 3, 7, 5, 2, 6, 4), (1\n",
      "      259 nodes |        0 goal |    6 cost |      43 actions | PancakeProblem((1, 7, 2, 6, 3, 5, 4), (1\n",
      "   24,606 nodes |        0 goal |    9 cost |   2,743 actions | PancakeProblem((1, 3, 5, 7, 9, 2, 4, 6, \n",
      "   26,797 nodes |        0 goal |   30 cost |   3,092 actions | TOTAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report([astar_search, bidirectional_astar_search, uniform_cost_search, bidirectional_uniform_cost_search], [c1, c2, c3, c4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos explorar casi 300 veces más nodos sin la heurística."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
